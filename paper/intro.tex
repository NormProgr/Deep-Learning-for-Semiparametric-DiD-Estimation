\section{Introduction}



% Issues and importance of Inference and DIfference in Difference and how Deep Learning could tackle that
The evaluation of policy changes is crucial in economics and other social sciences, as it determines the effectiveness of governmental interventions.
To deliver accurate evaluations in these quasi-experimental settings, researchers use the widely applied \ac{did} method.
\ac{did} is an econometric method to estimate the effect of a policy change on a group of individuals, known as the treatment group.
To achieve this, the method requires comparing treatment group and a control group before and after the policy change.
The critical underlying assumption is the \ac{pta}, which states that the treatment and control group would have developed similarly without the policy change.
This assumption is essential to identify the causal effect on the treatment group, referred to as the \ac{att}.

In practice, it is impossible to verify if the \ac{pta} holds, as it is by design untestable.
If individuals are selected for treatment based on characteristics that influence the outcome, the \ac{pta} is violated.
To address  this issue, researchers condition on these characteristics, assuming conditional \ac{pta} \citep[see][]{santannaDoublyRobustDifferenceindifferences2020,manfeDifferenceInDifferenceDesignRepeated}

This thesis explores how researchers can use more flexible semiparametric approaches to achieve robust \ac{did} estimation under the conditional \ac{pta}.
A variety of machine and deep learning models are considered to replace the first-step estimation in the \ac{did} framework.
Especially the use of deep learning marks a novelty and I follow \citet{farrellDeepNeuralNetworks2021} to contribute to the young but growing literature.

This thesis aims to contribute to the literature in four ways.
First, I review the current state of classical and machine learning techniques used for \ac{did} estimation.
This includes revisiting the classic \ac{did} estimation with \ac{twfe} and semiparametric approaches such as \ac{or} \citep[see][]{heckmanMatchingEconometricEvaluation1998}, \ac{ipw} \citep[see][]{abadieSemiparametricDifferenceinDifferencesEstimators2005}, and \ac{drdid} \citep[see][]{santannaDoublyRobustDifferenceindifferences2020}.

Second, I introduce a new approach using deep learning for first-step \ac{did} estimation.
As the literature is rather new, I aim to review how deep neural networks work and why they are a valid approach for inference, following the results of \citet{farrellDeepNeuralNetworks2021}.

Third, I conduct a \ac{mcs} to compare the performance of traditional techniques with deep learning variations of the \ac{ipw} and \ac{drdid} approaches.
The simulation design follows \citet{santannaDoublyRobustDifferenceindifferences2020}, using a \ac{dgp} for panel data with four variations.
The variations differ whether the outcome was generated correctly by \ac{or} or \ac{ipw}, both or none.
The results show that deep learning approaches perform nearly as well as the best traditional estimators in the first three variations and outperform others when the outcome is not correctly specified by any estimation strategy.
Additionally, I introduce heterogeneity in treatment for the incorrectly specified case and show that the \ac{drdid} deep learning case is the best-performing technique.
These results suggest that deep learning is a valid approach for first-step estimation, especially when imposing few restrictions on the \ac{did} model.

Lastly, I want to apply these techniques to a real-world dataset of \citet{meyer1990workers} to show the potential of the \ac{drdid} deep learning estimator. %explain more
The estimator shows promising results, robust to heterogeneous treatment effects and under conditional \ac{pta}.

% add here a part were I say what for issues I had and what problems I encountered
Finally, this thesis cannot cover all aspects relevant to semiparametric \ac{did} estimation.
It is crucial to emphasize the sensitivity of semiparametric estimators to the selection of the \ac{dgp}, especially in low-dimensional examples such as here \ac{dgp} \citep{zimmert2018efficient}.
More research is needed to apply deep learning to other DGPs, such as repeated cross-sectional data.
Additionally, this thesis focuses on the simple 2x2 \ac{did} setting, excluding more complex scenarios like multiple treatment groups or multiple periods \citep[see][]{callawayDifferenceinDifferencesMultipleTime2021,goodman-baconDifferenceindifferencesVariationTreatment2021}.
Further research is required to develop more computationally efficient deep learning models, making these methods more accessible to econometric practitioners.

The remainder of the thesis is structured as follows: Section I introduces the methodology of all techniques used in this thesis.
Section II introduces deep learning in general and its use for inference.
Section III introduces the \ac{mcs} and its results.
Section IV applies the techniques to a real-world dataset.
Section V discusses the results and implications.
Section VI concludes the thesis.

\noindent\rule{3cm}{0.5pt} % Horizontal line

\small The code can be found on GitHub for replication purposes:
\url{https://github.com/NormProgr/Deep-Learning-for-Semiparametric-DiD-Estimation.git}.
% Organization of the paper
