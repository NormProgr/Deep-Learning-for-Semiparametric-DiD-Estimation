{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGP1 \n",
    "NON-RANDOMIZED EXPERIMENT WITH X-SPECIFIC TRENDS PROPENSITY SCORES CORRECTLY SPECIFIED, OUTCOME REGRESSION CORRECTLY SPECIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DGP1\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit as logistic_cdf\n",
    "from scipy.stats import iqr, norm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def std_ipw_did_rc(\n",
    "    y,\n",
    "    post,\n",
    "    D,\n",
    "    covariates=None,\n",
    "    i_weights=None,\n",
    "    boot=False,\n",
    "    boot_type=\"weighted\",\n",
    "    nboot=None,\n",
    "    inffunc=False,\n",
    "):\n",
    "    # Convert inputs to numpy arrays\n",
    "    D = np.asarray(D).flatten()\n",
    "    n = len(D)\n",
    "    y = np.asarray(y).flatten()\n",
    "    post = np.asarray(post).flatten()\n",
    "\n",
    "    # Add constant to covariate vector\n",
    "    if covariates is None:\n",
    "        int_cov = np.ones((n, 1))\n",
    "    else:\n",
    "        covariates = np.asarray(covariates)\n",
    "        if np.all(covariates[:, 0] == 1):\n",
    "            int_cov = covariates\n",
    "        else:\n",
    "            int_cov = np.hstack((np.ones((n, 1)), covariates))\n",
    "\n",
    "    # Weights\n",
    "    if i_weights is None:\n",
    "        i_weights = np.ones(n)\n",
    "    elif np.min(i_weights) < 0:\n",
    "        msg = \"i.weights must be non-negative\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # Pscore estimation (logit) and its fitted values\n",
    "    model = LogisticRegression(fit_intercept=False, solver=\"lbfgs\")\n",
    "    model.fit(int_cov, D, sample_weight=i_weights)\n",
    "    ps_fit = model.predict_proba(int_cov)[:, 1]\n",
    "\n",
    "    # Do not divide by zero\n",
    "    ps_fit = np.clip(ps_fit, 1e-16, 1 - 1e-16)\n",
    "\n",
    "    # Compute IPW estimator\n",
    "    w_treat_pre = i_weights * D * (1 - post)\n",
    "    w_treat_post = i_weights * D * post\n",
    "    w_cont_pre = i_weights * ps_fit * (1 - D) * (1 - post) / (1 - ps_fit)\n",
    "    w_cont_post = i_weights * ps_fit * (1 - D) * post / (1 - ps_fit)\n",
    "\n",
    "    # Elements of the influence function (summands)\n",
    "    eta_treat_pre = w_treat_pre * y / np.mean(w_treat_pre)\n",
    "    eta_treat_post = w_treat_post * y / np.mean(w_treat_post)\n",
    "    eta_cont_pre = w_cont_pre * y / np.mean(w_cont_pre)\n",
    "    eta_cont_post = w_cont_post * y / np.mean(w_cont_post)\n",
    "\n",
    "    # Estimator of each component\n",
    "    att_treat_pre = np.mean(eta_treat_pre)\n",
    "    att_treat_post = np.mean(eta_treat_post)\n",
    "    att_cont_pre = np.mean(eta_cont_pre)\n",
    "    att_cont_post = np.mean(eta_cont_post)\n",
    "\n",
    "    # ATT estimator\n",
    "    ipw_att = (att_treat_post - att_treat_pre) - (att_cont_post - att_cont_pre)\n",
    "\n",
    "    # Get the influence function to compute standard error\n",
    "    score_ps = i_weights.reshape(-1, 1) * (D - ps_fit).reshape(-1, 1) * int_cov\n",
    "    hessian_ps = np.linalg.inv(np.dot(score_ps.T, score_ps) / n)\n",
    "    asy_lin_rep_ps = np.dot(score_ps, hessian_ps)\n",
    "\n",
    "    # Influence function of the \"treat\" component\n",
    "    inf_treat_pre = eta_treat_pre - w_treat_pre * att_treat_pre / np.mean(w_treat_pre)\n",
    "    inf_treat_post = eta_treat_post - w_treat_post * att_treat_post / np.mean(\n",
    "        w_treat_post,\n",
    "    )\n",
    "    inf_treat = inf_treat_post - inf_treat_pre\n",
    "\n",
    "    # Influence function of the control component\n",
    "    inf_cont_pre = eta_cont_pre - w_cont_pre * att_cont_pre / np.mean(w_cont_pre)\n",
    "    inf_cont_post = eta_cont_post - w_cont_post * att_cont_post / np.mean(w_cont_post)\n",
    "    inf_cont = inf_cont_post - inf_cont_pre\n",
    "\n",
    "    # Estimation effect from gamma hat (pscore)\n",
    "    M2_pre = np.mean(\n",
    "        w_cont_pre.reshape(-1, 1)\n",
    "        * (y - att_cont_pre).reshape(-1, 1)\n",
    "        * int_cov\n",
    "        / np.mean(w_cont_pre),\n",
    "        axis=0,\n",
    "    )\n",
    "    M2_post = np.mean(\n",
    "        w_cont_post.reshape(-1, 1)\n",
    "        * (y - att_cont_post).reshape(-1, 1)\n",
    "        * int_cov\n",
    "        / np.mean(w_cont_post),\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    inf_cont_ps = np.dot(asy_lin_rep_ps, (M2_post - M2_pre))\n",
    "    inf_cont += inf_cont_ps\n",
    "\n",
    "    # Influence function of the DR estimator\n",
    "    att_inf_func = inf_treat - inf_cont\n",
    "\n",
    "    if not boot:\n",
    "        # Estimate standard error\n",
    "        se_att = np.std(att_inf_func) / np.sqrt(n)\n",
    "        uci = ipw_att + 1.96 * se_att\n",
    "        lci = ipw_att - 1.96 * se_att\n",
    "        ipw_boot = None\n",
    "    else:\n",
    "        if nboot is None:\n",
    "            nboot = 999\n",
    "        if boot_type == \"multiplier\":\n",
    "            # Multiplier bootstrap\n",
    "            multipliers = np.random.normal(size=(nboot, n))\n",
    "            ipw_boot = [np.mean(m * att_inf_func) for m in multipliers]\n",
    "            se_att = iqr(ipw_boot) / (norm.ppf(0.75) - norm.ppf(0.25))\n",
    "            cv = np.percentile(np.abs(ipw_boot / se_att), 95)\n",
    "            uci = ipw_att + cv * se_att\n",
    "            lci = ipw_att - cv * se_att\n",
    "        else:\n",
    "            # Weighted bootstrap\n",
    "            ipw_boot = [\n",
    "                wboot_std_ipw_rc(n, y, post, D, int_cov, i_weights)\n",
    "                for _ in range(nboot)\n",
    "            ]\n",
    "            se_att = iqr(ipw_boot - ipw_att) / (norm.ppf(0.75) - norm.ppf(0.25))\n",
    "            cv = np.percentile(np.abs((ipw_boot - ipw_att) / se_att), 95)\n",
    "            uci = ipw_att + cv * se_att\n",
    "            lci = ipw_att - cv * se_att\n",
    "\n",
    "    if not inffunc:\n",
    "        att_inf_func = None\n",
    "\n",
    "    return {\n",
    "        \"ATT\": ipw_att,\n",
    "        \"se\": se_att,\n",
    "        \"uci\": uci,\n",
    "        \"lci\": lci,\n",
    "        \"boots\": ipw_boot,\n",
    "        \"att_inf_func\": att_inf_func,\n",
    "    }\n",
    "\n",
    "\n",
    "def wboot_std_ipw_rc(n, y, post, D, int_cov, i_weights):\n",
    "    boot_weights = np.random.choice(np.arange(1, n + 1), size=n, replace=True)\n",
    "    return std_ipw_did_rc(y, post, D, int_cov, i_weights=boot_weights)[\"ATT\"]\n",
    "\n",
    "\n",
    "# Simulation setup\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def ipw_sim_run():\n",
    "    # Define parameters\n",
    "    n = 1000  # Sample size\n",
    "    Xsi_ps = 0.75  # pscore index\n",
    "    _lambda = 0.5  # Proportion in each period\n",
    "\n",
    "    # Define means and standard deviations\n",
    "    mean_z1 = np.exp(0.25 / 2)\n",
    "    sd_z1 = np.sqrt((np.exp(0.25) - 1) * np.exp(0.25))\n",
    "    mean_z2 = 10\n",
    "    sd_z2 = 0.54164\n",
    "    mean_z3 = 0.21887\n",
    "    sd_z3 = 0.04453\n",
    "    mean_z4 = 402\n",
    "    sd_z4 = 56.63891\n",
    "\n",
    "    # Initialize empty lists to store results\n",
    "    ATTE_estimates = []\n",
    "    asymptotic_variance = []\n",
    "\n",
    "    # Loop for 100 runs\n",
    "    for _i in range(1000):\n",
    "        # Generate covariates\n",
    "        x1 = np.random.normal(0, 1, n)\n",
    "        x2 = np.random.normal(0, 1, n)\n",
    "        x3 = np.random.normal(0, 1, n)\n",
    "        x4 = np.random.normal(0, 1, n)\n",
    "\n",
    "        z1 = np.exp(x1 / 2)\n",
    "        z2 = x2 / (1 + np.exp(x1)) + 10\n",
    "        z3 = (x1 * x3 / 25 + 0.6) ** 3\n",
    "        z4 = (x1 + x4 + 20) ** 2\n",
    "\n",
    "        z1 = (z1 - mean_z1) / sd_z1\n",
    "        z2 = (z2 - mean_z2) / sd_z2\n",
    "        z3 = (z3 - mean_z3) / sd_z3\n",
    "        z4 = (z4 - mean_z4) / sd_z4\n",
    "\n",
    "        # Propensity score\n",
    "        pi = logistic_cdf(Xsi_ps * (-z1 + 0.5 * z2 - 0.25 * z3 - 0.1 * z4))\n",
    "        d = np.random.uniform(size=n) <= pi\n",
    "\n",
    "        # Generate aux indexes for the potential outcomes\n",
    "        index_lin = 210 + 27.4 * z1 + 13.7 * (z2 + z3 + z4)\n",
    "        index_unobs_het = d * index_lin\n",
    "        index_att = 0\n",
    "        index_trend = 210 + 27.4 * z1 + 13.7 * (z2 + z3 + z4)\n",
    "\n",
    "        # Generate unobserved heterogeneity\n",
    "        v = np.random.normal(index_unobs_het, 1)\n",
    "\n",
    "        # Generate outcomes at time 0 and time 1\n",
    "        y00 = index_lin + v + np.random.normal(size=n)\n",
    "        y10 = index_lin + v + np.random.normal(size=n)\n",
    "        y01 = index_lin + v + np.random.normal(scale=1, size=n) + index_trend\n",
    "        y11 = (\n",
    "            index_lin + v + np.random.normal(scale=1, size=n) + index_trend + index_att\n",
    "        )\n",
    "\n",
    "        # Generate \"T\"\n",
    "        ti_nt = 0.5\n",
    "        ti_t = 0.5\n",
    "        ti = d * ti_t + (1 - d) * ti_nt\n",
    "        post = np.random.uniform(size=n) <= ti\n",
    "\n",
    "        y = np.where(\n",
    "            d & post,\n",
    "            y11,\n",
    "            np.where(~d & post, y01, np.where(~d & ~post, y00, y10)),\n",
    "        )\n",
    "\n",
    "        # Generate id\n",
    "        id_ = np.repeat(np.arange(1, n + 1), 2)\n",
    "        time = np.tile([0, 1], n)\n",
    "\n",
    "        # Put in a long data frame\n",
    "        dta_long = pd.DataFrame(\n",
    "            {\n",
    "                \"id\": id_,\n",
    "                \"time\": time,\n",
    "                \"y\": np.tile(y, 2),\n",
    "                \"post\": np.tile(post.astype(int), 2),\n",
    "                \"d\": np.tile(d.astype(int), 2),\n",
    "                \"x1\": np.tile(z1, 2),\n",
    "                \"x2\": np.tile(z2, 2),\n",
    "                \"x3\": np.tile(z3, 2),\n",
    "                \"x4\": np.tile(z4, 2),\n",
    "            },\n",
    "        )\n",
    "        dta_long[\"post:d\"] = dta_long[\"post\"] * dta_long[\"d\"]\n",
    "        dta_long = dta_long.sort_values([\"id\", \"time\"])\n",
    "\n",
    "        # Run the IPW-DID estimator\n",
    "        covariates = dta_long[[\"x1\", \"x2\", \"x3\", \"x4\"]].values\n",
    "        y = dta_long[\"y\"].values\n",
    "        post = dta_long[\"post\"].values\n",
    "        D = dta_long[\"d\"].values\n",
    "\n",
    "        result = std_ipw_did_rc(y, post, D, covariates)\n",
    "\n",
    "        ATTE_estimates.append(result[\"ATT\"])\n",
    "        asymptotic_variance.append(result[\"se\"] ** 2)\n",
    "\n",
    "    # Calculate average bias, median bias, and RMSE\n",
    "    true_ATT = 0\n",
    "\n",
    "    # Bias calculations\n",
    "    biases = np.array(ATTE_estimates) - true_ATT\n",
    "    average_bias = np.mean(biases)\n",
    "    median_bias = np.median(biases)\n",
    "    average_variance = np.mean(asymptotic_variance)\n",
    "    # RMSE calculation\n",
    "    rmse = np.sqrt(np.mean(biases**2))\n",
    "\n",
    "    # Display the results\n",
    "    return {\n",
    "        \"Average Bias\": average_bias,\n",
    "        \"Median Bias\": median_bias,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Average Variance of ATT\": average_variance,\n",
    "    }\n",
    "\n",
    "\n",
    "ipw_sim_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGP 2\n",
    "NON-RANDOMIZED EXPERIMENT WITH X-SPECIFIC TRENDS PROPENSITY SCORES NOT CORRECTLY SPECIFIED, OUTCOME REGRESSION CORRECTLY SPECIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit as logistic_cdf\n",
    "from scipy.stats import iqr, norm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def std_ipw_did_rc(\n",
    "    y,\n",
    "    post,\n",
    "    D,\n",
    "    covariates=None,\n",
    "    i_weights=None,\n",
    "    boot=False,\n",
    "    boot_type=\"weighted\",\n",
    "    nboot=None,\n",
    "    inffunc=False,\n",
    "):\n",
    "    # Convert inputs to numpy arrays\n",
    "    D = np.asarray(D).flatten()\n",
    "    n = len(D)\n",
    "    y = np.asarray(y).flatten()\n",
    "    post = np.asarray(post).flatten()\n",
    "\n",
    "    # Add constant to covariate vector\n",
    "    if covariates is None:\n",
    "        int_cov = np.ones((n, 1))\n",
    "    else:\n",
    "        covariates = np.asarray(covariates)\n",
    "        if np.all(covariates[:, 0] == 1):\n",
    "            int_cov = covariates\n",
    "        else:\n",
    "            int_cov = np.hstack((np.ones((n, 1)), covariates))\n",
    "\n",
    "    # Weights\n",
    "    if i_weights is None:\n",
    "        i_weights = np.ones(n)\n",
    "    elif np.min(i_weights) < 0:\n",
    "        msg = \"i.weights must be non-negative\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # Pscore estimation (logit) and its fitted values\n",
    "    model = LogisticRegression(fit_intercept=False, solver=\"lbfgs\")\n",
    "    model.fit(int_cov, D, sample_weight=i_weights)\n",
    "    ps_fit = model.predict_proba(int_cov)[:, 1]\n",
    "\n",
    "    # Do not divide by zero\n",
    "    ps_fit = np.clip(ps_fit, 1e-16, 1 - 1e-16)\n",
    "\n",
    "    # Compute IPW estimator\n",
    "    w_treat_pre = i_weights * D * (1 - post)\n",
    "    w_treat_post = i_weights * D * post\n",
    "    w_cont_pre = i_weights * ps_fit * (1 - D) * (1 - post) / (1 - ps_fit)\n",
    "    w_cont_post = i_weights * ps_fit * (1 - D) * post / (1 - ps_fit)\n",
    "\n",
    "    # Elements of the influence function (summands)\n",
    "    eta_treat_pre = w_treat_pre * y / np.mean(w_treat_pre)\n",
    "    eta_treat_post = w_treat_post * y / np.mean(w_treat_post)\n",
    "    eta_cont_pre = w_cont_pre * y / np.mean(w_cont_pre)\n",
    "    eta_cont_post = w_cont_post * y / np.mean(w_cont_post)\n",
    "\n",
    "    # Estimator of each component\n",
    "    att_treat_pre = np.mean(eta_treat_pre)\n",
    "    att_treat_post = np.mean(eta_treat_post)\n",
    "    att_cont_pre = np.mean(eta_cont_pre)\n",
    "    att_cont_post = np.mean(eta_cont_post)\n",
    "\n",
    "    # ATT estimator\n",
    "    ipw_att = (att_treat_post - att_treat_pre) - (att_cont_post - att_cont_pre)\n",
    "\n",
    "    # Get the influence function to compute standard error\n",
    "    score_ps = i_weights.reshape(-1, 1) * (D - ps_fit).reshape(-1, 1) * int_cov\n",
    "    hessian_ps = np.linalg.inv(np.dot(score_ps.T, score_ps) / n)\n",
    "    asy_lin_rep_ps = np.dot(score_ps, hessian_ps)\n",
    "\n",
    "    # Influence function of the \"treat\" component\n",
    "    inf_treat_pre = eta_treat_pre - w_treat_pre * att_treat_pre / np.mean(w_treat_pre)\n",
    "    inf_treat_post = eta_treat_post - w_treat_post * att_treat_post / np.mean(\n",
    "        w_treat_post,\n",
    "    )\n",
    "    inf_treat = inf_treat_post - inf_treat_pre\n",
    "\n",
    "    # Influence function of the control component\n",
    "    inf_cont_pre = eta_cont_pre - w_cont_pre * att_cont_pre / np.mean(w_cont_pre)\n",
    "    inf_cont_post = eta_cont_post - w_cont_post * att_cont_post / np.mean(w_cont_post)\n",
    "    inf_cont = inf_cont_post - inf_cont_pre\n",
    "\n",
    "    # Estimation effect from gamma hat (pscore)\n",
    "    M2_pre = np.mean(\n",
    "        w_cont_pre.reshape(-1, 1)\n",
    "        * (y - att_cont_pre).reshape(-1, 1)\n",
    "        * int_cov\n",
    "        / np.mean(w_cont_pre),\n",
    "        axis=0,\n",
    "    )\n",
    "    M2_post = np.mean(\n",
    "        w_cont_post.reshape(-1, 1)\n",
    "        * (y - att_cont_post).reshape(-1, 1)\n",
    "        * int_cov\n",
    "        / np.mean(w_cont_post),\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    inf_cont_ps = np.dot(asy_lin_rep_ps, (M2_post - M2_pre))\n",
    "    inf_cont += inf_cont_ps\n",
    "\n",
    "    # Influence function of the DR estimator\n",
    "    att_inf_func = inf_treat - inf_cont\n",
    "\n",
    "    if not boot:\n",
    "        # Estimate standard error\n",
    "        se_att = np.std(att_inf_func) / np.sqrt(n)\n",
    "        uci = ipw_att + 1.96 * se_att\n",
    "        lci = ipw_att - 1.96 * se_att\n",
    "        ipw_boot = None\n",
    "    else:\n",
    "        if nboot is None:\n",
    "            nboot = 999\n",
    "        if boot_type == \"multiplier\":\n",
    "            # Multiplier bootstrap\n",
    "            multipliers = np.random.normal(size=(nboot, n))\n",
    "            ipw_boot = [np.mean(m * att_inf_func) for m in multipliers]\n",
    "            se_att = iqr(ipw_boot) / (norm.ppf(0.75) - norm.ppf(0.25))\n",
    "            cv = np.percentile(np.abs(ipw_boot / se_att), 95)\n",
    "            uci = ipw_att + cv * se_att\n",
    "            lci = ipw_att - cv * se_att\n",
    "        else:\n",
    "            # Weighted bootstrap\n",
    "            ipw_boot = [\n",
    "                wboot_std_ipw_rc(n, y, post, D, int_cov, i_weights)\n",
    "                for _ in range(nboot)\n",
    "            ]\n",
    "            se_att = iqr(ipw_boot - ipw_att) / (norm.ppf(0.75) - norm.ppf(0.25))\n",
    "            cv = np.percentile(np.abs((ipw_boot - ipw_att) / se_att), 95)\n",
    "            uci = ipw_att + cv * se_att\n",
    "            lci = ipw_att - cv * se_att\n",
    "\n",
    "    if not inffunc:\n",
    "        att_inf_func = None\n",
    "\n",
    "    return {\n",
    "        \"ATT\": ipw_att,\n",
    "        \"se\": se_att,\n",
    "        \"uci\": uci,\n",
    "        \"lci\": lci,\n",
    "        \"boots\": ipw_boot,\n",
    "        \"att_inf_func\": att_inf_func,\n",
    "    }\n",
    "\n",
    "\n",
    "def wboot_std_ipw_rc(n, y, post, D, int_cov, i_weights):\n",
    "    boot_weights = np.random.choice(np.arange(1, n + 1), size=n, replace=True)\n",
    "    return std_ipw_did_rc(y, post, D, int_cov, i_weights=boot_weights)[\"ATT\"]\n",
    "\n",
    "\n",
    "# Simulation setup\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def ipw_sim_run():\n",
    "    # Define parameters\n",
    "    np.random.seed(42)  # You can use any integer value as the seed\n",
    "\n",
    "    # Sample size\n",
    "    n = 1000\n",
    "    # pscore index (strength of common support)\n",
    "    Xsi_ps = 0.75\n",
    "    # Proportion in each period\n",
    "    _lambda = 0.5\n",
    "    # Number of bootstrapped draws\n",
    "\n",
    "    # Mean and Std deviation of Z's without truncation\n",
    "    mean_z1 = np.exp(0.25 / 2)\n",
    "    sd_z1 = np.sqrt((np.exp(0.25) - 1) * np.exp(0.25))\n",
    "    mean_z2 = 10\n",
    "    sd_z2 = 0.54164\n",
    "    mean_z3 = 0.21887\n",
    "    sd_z3 = 0.04453\n",
    "    mean_z4 = 402\n",
    "    sd_z4 = 56.63891\n",
    "\n",
    "    # Initialize empty lists to store results\n",
    "    ATTE_estimates = []\n",
    "    asymptotic_variance = []\n",
    "\n",
    "    for _i in range(1000):\n",
    "        # Generate covariates\n",
    "        x1 = np.random.normal(0, 1, n)\n",
    "        x2 = np.random.normal(0, 1, n)\n",
    "        x3 = np.random.normal(0, 1, n)\n",
    "        x4 = np.random.normal(0, 1, n)\n",
    "\n",
    "        z1 = np.exp(x1 / 2)\n",
    "        z2 = x2 / (1 + np.exp(x1)) + 10\n",
    "        z3 = (x1 * x3 / 25 + 0.6) ** 3\n",
    "        z4 = (x1 + x4 + 20) ** 2\n",
    "\n",
    "        z1 = (z1 - mean_z1) / sd_z1\n",
    "        z2 = (z2 - mean_z2) / sd_z2\n",
    "        z3 = (z3 - mean_z3) / sd_z3\n",
    "        z4 = (z4 - mean_z4) / sd_z4\n",
    "\n",
    "        np.column_stack((x1, x2, x3, x4))\n",
    "        np.column_stack((z1, z2, z3, z4))\n",
    "\n",
    "        # Generate treatment groups\n",
    "        # Propensity score\n",
    "        pi = logistic_cdf(Xsi_ps * (-x1 + 0.5 * x2 - 0.25 * x3 - 0.1 * x4))\n",
    "        d = np.random.uniform(size=n) <= pi\n",
    "\n",
    "        # Generate aux indexes for the potential outcomes\n",
    "        index_lin = 210 + 27.4 * z1 + 13.7 * (z2 + z3 + z4)\n",
    "\n",
    "        # Create heterogenenous effects for the ATT, which is set approximately equal to zero\n",
    "        index_unobs_het = d * (index_lin)\n",
    "        index_att = 0\n",
    "\n",
    "        # This is the key for consistency of outcome regression\n",
    "        index_trend = 210 + 27.4 * z1 + 13.7 * (z2 + z3 + z4)\n",
    "\n",
    "        # v is the unobserved heterogeneity\n",
    "        v = np.random.normal(index_unobs_het, 1)\n",
    "\n",
    "        # Gen realized outcome at time 0\n",
    "        y00 = index_lin + v + np.random.normal(size=n)\n",
    "        y10 = index_lin + v + np.random.normal(size=n)\n",
    "\n",
    "        # Gen outcomes at time 1\n",
    "        # First let's generate potential outcomes: y_1_potential\n",
    "        y01 = (\n",
    "            index_lin + v + np.random.normal(scale=1, size=n) + index_trend\n",
    "        )  # This is the baseline\n",
    "        y11 = (\n",
    "            index_lin + v + np.random.normal(scale=1, size=n) + index_trend + index_att\n",
    "        )  # This is the baseline\n",
    "\n",
    "        # Generate \"T\"\n",
    "        ti_nt = 0.5\n",
    "        ti_t = 0.5\n",
    "        ti = d * ti_t + (1 - d) * ti_nt\n",
    "        post = np.random.uniform(size=n) <= ti\n",
    "\n",
    "        y = np.where(\n",
    "            d & post,\n",
    "            y11,\n",
    "            np.where(~d & post, y01, np.where(~d & ~post, y00, y10)),\n",
    "        )\n",
    "\n",
    "        # Gen id\n",
    "        id_ = np.repeat(np.arange(1, n + 1), 2)\n",
    "        time = np.tile([0, 1], n)\n",
    "\n",
    "        # Put in a long data frame\n",
    "        dta_long = pd.DataFrame(\n",
    "            {\n",
    "                \"id\": id_,\n",
    "                \"time\": time,\n",
    "                \"y\": np.tile(y, 2),\n",
    "                \"post\": np.tile(post.astype(int), 2),\n",
    "                \"d\": np.tile(d.astype(int), 2),\n",
    "                \"x1\": np.tile(z1, 2),\n",
    "                \"x2\": np.tile(z2, 2),\n",
    "                \"x3\": np.tile(z3, 2),\n",
    "                \"x4\": np.tile(z4, 2),\n",
    "            },\n",
    "        )\n",
    "        dta_long[\"post:d\"] = dta_long[\"post\"] * dta_long[\"d\"]\n",
    "        dta_long = dta_long.sort_values([\"id\", \"time\"])\n",
    "\n",
    "        # Run the IPW-DID estimator\n",
    "        covariates = dta_long[[\"x1\", \"x2\", \"x3\", \"x4\"]].values\n",
    "        y = dta_long[\"y\"].values\n",
    "        post = dta_long[\"post\"].values\n",
    "        D = dta_long[\"d\"].values\n",
    "\n",
    "        result = std_ipw_did_rc(y, post, D, covariates)\n",
    "\n",
    "        ATTE_estimates.append(result[\"ATT\"])\n",
    "        asymptotic_variance.append(result[\"se\"] ** 2)\n",
    "\n",
    "    # Calculate average bias, median bias, and RMSE\n",
    "    true_ATT = 0\n",
    "\n",
    "    # Bias calculations\n",
    "    biases = np.array(ATTE_estimates) - true_ATT\n",
    "    average_bias = np.mean(biases)\n",
    "    median_bias = np.median(biases)\n",
    "    average_variance = np.mean(asymptotic_variance)\n",
    "    # RMSE calculation\n",
    "    rmse = np.sqrt(np.mean(biases**2))\n",
    "\n",
    "    # Display the results\n",
    "    return {\n",
    "        \"Average Bias\": average_bias,\n",
    "        \"Median Bias\": median_bias,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Average Variance of ATT\": average_variance,\n",
    "    }\n",
    "\n",
    "\n",
    "ipw_sim_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGP3 Abadie\n",
    "EXPERIMENT 1C: NON-RANDOMIZED EXPERIMENT WITH X-SPECIFIC TRENDS     PROPENSITY SCORES CORRECTLY SPECIFIED, OUTCOME REGRESSION NOT CORRECTLY SPECIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit as logistic_cdf\n",
    "from scipy.stats import iqr, norm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def std_ipw_did_rc(\n",
    "    y,\n",
    "    post,\n",
    "    D,\n",
    "    covariates=None,\n",
    "    i_weights=None,\n",
    "    boot=False,\n",
    "    boot_type=\"weighted\",\n",
    "    nboot=None,\n",
    "    inffunc=False,\n",
    "):\n",
    "    # Convert inputs to numpy arrays\n",
    "    D = np.asarray(D).flatten()\n",
    "    n = len(D)\n",
    "    y = np.asarray(y).flatten()\n",
    "    post = np.asarray(post).flatten()\n",
    "\n",
    "    # Add constant to covariate vector\n",
    "    if covariates is None:\n",
    "        int_cov = np.ones((n, 1))\n",
    "    else:\n",
    "        covariates = np.asarray(covariates)\n",
    "        if np.all(covariates[:, 0] == 1):\n",
    "            int_cov = covariates\n",
    "        else:\n",
    "            int_cov = np.hstack((np.ones((n, 1)), covariates))\n",
    "\n",
    "    # Weights\n",
    "    if i_weights is None:\n",
    "        i_weights = np.ones(n)\n",
    "    elif np.min(i_weights) < 0:\n",
    "        msg = \"i.weights must be non-negative\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # Pscore estimation (logit) and its fitted values\n",
    "    model = LogisticRegression(fit_intercept=False, solver=\"lbfgs\")\n",
    "    model.fit(int_cov, D, sample_weight=i_weights)\n",
    "    ps_fit = model.predict_proba(int_cov)[:, 1]\n",
    "\n",
    "    # Do not divide by zero\n",
    "    ps_fit = np.clip(ps_fit, 1e-16, 1 - 1e-16)\n",
    "\n",
    "    # Compute IPW estimator\n",
    "    w_treat_pre = i_weights * D * (1 - post)\n",
    "    w_treat_post = i_weights * D * post\n",
    "    w_cont_pre = i_weights * ps_fit * (1 - D) * (1 - post) / (1 - ps_fit)\n",
    "    w_cont_post = i_weights * ps_fit * (1 - D) * post / (1 - ps_fit)\n",
    "\n",
    "    # Elements of the influence function (summands)\n",
    "    eta_treat_pre = w_treat_pre * y / np.mean(w_treat_pre)\n",
    "    eta_treat_post = w_treat_post * y / np.mean(w_treat_post)\n",
    "    eta_cont_pre = w_cont_pre * y / np.mean(w_cont_pre)\n",
    "    eta_cont_post = w_cont_post * y / np.mean(w_cont_post)\n",
    "\n",
    "    # Estimator of each component\n",
    "    att_treat_pre = np.mean(eta_treat_pre)\n",
    "    att_treat_post = np.mean(eta_treat_post)\n",
    "    att_cont_pre = np.mean(eta_cont_pre)\n",
    "    att_cont_post = np.mean(eta_cont_post)\n",
    "\n",
    "    # ATT estimator\n",
    "    ipw_att = (att_treat_post - att_treat_pre) - (att_cont_post - att_cont_pre)\n",
    "\n",
    "    # Get the influence function to compute standard error\n",
    "    score_ps = i_weights.reshape(-1, 1) * (D - ps_fit).reshape(-1, 1) * int_cov\n",
    "    hessian_ps = np.linalg.inv(np.dot(score_ps.T, score_ps) / n)\n",
    "    asy_lin_rep_ps = np.dot(score_ps, hessian_ps)\n",
    "\n",
    "    # Influence function of the \"treat\" component\n",
    "    inf_treat_pre = eta_treat_pre - w_treat_pre * att_treat_pre / np.mean(w_treat_pre)\n",
    "    inf_treat_post = eta_treat_post - w_treat_post * att_treat_post / np.mean(\n",
    "        w_treat_post,\n",
    "    )\n",
    "    inf_treat = inf_treat_post - inf_treat_pre\n",
    "\n",
    "    # Influence function of the control component\n",
    "    inf_cont_pre = eta_cont_pre - w_cont_pre * att_cont_pre / np.mean(w_cont_pre)\n",
    "    inf_cont_post = eta_cont_post - w_cont_post * att_cont_post / np.mean(w_cont_post)\n",
    "    inf_cont = inf_cont_post - inf_cont_pre\n",
    "\n",
    "    # Estimation effect from gamma hat (pscore)\n",
    "    M2_pre = np.mean(\n",
    "        w_cont_pre.reshape(-1, 1)\n",
    "        * (y - att_cont_pre).reshape(-1, 1)\n",
    "        * int_cov\n",
    "        / np.mean(w_cont_pre),\n",
    "        axis=0,\n",
    "    )\n",
    "    M2_post = np.mean(\n",
    "        w_cont_post.reshape(-1, 1)\n",
    "        * (y - att_cont_post).reshape(-1, 1)\n",
    "        * int_cov\n",
    "        / np.mean(w_cont_post),\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    inf_cont_ps = np.dot(asy_lin_rep_ps, (M2_post - M2_pre))\n",
    "    inf_cont += inf_cont_ps\n",
    "\n",
    "    # Influence function of the DR estimator\n",
    "    att_inf_func = inf_treat - inf_cont\n",
    "\n",
    "    if not boot:\n",
    "        # Estimate standard error\n",
    "        se_att = np.std(att_inf_func) / np.sqrt(n)\n",
    "        uci = ipw_att + 1.96 * se_att\n",
    "        lci = ipw_att - 1.96 * se_att\n",
    "        ipw_boot = None\n",
    "    else:\n",
    "        if nboot is None:\n",
    "            nboot = 999\n",
    "        if boot_type == \"multiplier\":\n",
    "            # Multiplier bootstrap\n",
    "            multipliers = np.random.normal(size=(nboot, n))\n",
    "            ipw_boot = [np.mean(m * att_inf_func) for m in multipliers]\n",
    "            se_att = iqr(ipw_boot) / (norm.ppf(0.75) - norm.ppf(0.25))\n",
    "            cv = np.percentile(np.abs(ipw_boot / se_att), 95)\n",
    "            uci = ipw_att + cv * se_att\n",
    "            lci = ipw_att - cv * se_att\n",
    "        else:\n",
    "            # Weighted bootstrap\n",
    "            ipw_boot = [\n",
    "                wboot_std_ipw_rc(n, y, post, D, int_cov, i_weights)\n",
    "                for _ in range(nboot)\n",
    "            ]\n",
    "            se_att = iqr(ipw_boot - ipw_att) / (norm.ppf(0.75) - norm.ppf(0.25))\n",
    "            cv = np.percentile(np.abs((ipw_boot - ipw_att) / se_att), 95)\n",
    "            uci = ipw_att + cv * se_att\n",
    "            lci = ipw_att - cv * se_att\n",
    "\n",
    "    if not inffunc:\n",
    "        att_inf_func = None\n",
    "\n",
    "    return {\n",
    "        \"ATT\": ipw_att,\n",
    "        \"se\": se_att,\n",
    "        \"uci\": uci,\n",
    "        \"lci\": lci,\n",
    "        \"boots\": ipw_boot,\n",
    "        \"att_inf_func\": att_inf_func,\n",
    "    }\n",
    "\n",
    "\n",
    "def wboot_std_ipw_rc(n, y, post, D, int_cov, i_weights):\n",
    "    boot_weights = np.random.choice(np.arange(1, n + 1), size=n, replace=True)\n",
    "    return std_ipw_did_rc(y, post, D, int_cov, i_weights=boot_weights)[\"ATT\"]\n",
    "\n",
    "\n",
    "# New Simulation setup\n",
    "\n",
    "\n",
    "def ipw_sim_run():\n",
    "    # Define parameters\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Sample size\n",
    "    n = 1000\n",
    "    # pscore index (strength of common support)\n",
    "    Xsi_ps = 0.75\n",
    "    # Proportion in each period\n",
    "    # Number of bootstrapped draws\n",
    "\n",
    "    # Mean and Std deviation of Z's without truncation\n",
    "    mean_z1 = np.exp(0.25 / 2)\n",
    "    sd_z1 = np.sqrt((np.exp(0.25) - 1) * np.exp(0.25))\n",
    "    mean_z2 = 10\n",
    "    sd_z2 = 0.54164\n",
    "    mean_z3 = 0.21887\n",
    "    sd_z3 = 0.04453\n",
    "    mean_z4 = 402\n",
    "    sd_z4 = 56.63891\n",
    "\n",
    "    # Initialize empty lists to store results\n",
    "    ATTE_estimates = []\n",
    "    asymptotic_variance = []\n",
    "\n",
    "    for _i in range(1000):\n",
    "        # Generate covariates\n",
    "        x1 = np.random.normal(0, 1, n)\n",
    "        x2 = np.random.normal(0, 1, n)\n",
    "        x3 = np.random.normal(0, 1, n)\n",
    "        x4 = np.random.normal(0, 1, n)\n",
    "\n",
    "        z1 = np.exp(x1 / 2)\n",
    "        z2 = x2 / (1 + np.exp(x1)) + 10\n",
    "        z3 = (x1 * x3 / 25 + 0.6) ** 3\n",
    "        z4 = (x1 + x4 + 20) ** 2\n",
    "\n",
    "        z1 = (z1 - mean_z1) / sd_z1\n",
    "        z2 = (z2 - mean_z2) / sd_z2\n",
    "        z3 = (z3 - mean_z3) / sd_z3\n",
    "        z4 = (z4 - mean_z4) / sd_z4\n",
    "\n",
    "        np.column_stack((x1, x2, x3, x4))\n",
    "        np.column_stack((z1, z2, z3, z4))\n",
    "\n",
    "        # Propensity score\n",
    "        pi = logistic_cdf(Xsi_ps * (-z1 + 0.5 * z2 - 0.25 * z3 - 0.1 * z4))\n",
    "        d = (np.random.uniform(size=n) <= pi).astype(int)\n",
    "\n",
    "        # Generate aux indexes for the potential outcomes\n",
    "        index_lin = 210 + 27.4 * x1 + 13.7 * (x2 + x3 + x4)\n",
    "\n",
    "        # Create heterogeneous effects for the ATT, which is set approximately equal to zero\n",
    "        index_unobs_het = d * index_lin\n",
    "        index_att = 0\n",
    "\n",
    "        # This is the key for consistency of outcome regression\n",
    "        index_trend = 210 + 27.4 * x1 + 13.7 * (x2 + x3 + x4)\n",
    "        # v is the unobserved heterogeneity\n",
    "        v = np.random.normal(index_unobs_het, 1)\n",
    "\n",
    "        # Gen realized outcome at time 0\n",
    "        y00 = index_lin + v + np.random.normal(size=n)\n",
    "        y10 = index_lin + v + np.random.normal(size=n)\n",
    "\n",
    "        # Gen outcomes at time 1\n",
    "        y01 = (\n",
    "            index_lin + v + np.random.normal(size=n) + index_trend\n",
    "        )  # This is the baseline\n",
    "        y11 = (\n",
    "            index_lin + v + np.random.normal(size=n) + index_trend + index_att\n",
    "        )  # This is the baseline\n",
    "\n",
    "        # Generate \"T\"\n",
    "        ti_nt = 0.5\n",
    "        ti_t = 0.5\n",
    "        ti = d * ti_t + (1 - d) * ti_nt\n",
    "        post = (np.random.uniform(size=n) <= ti).astype(int)\n",
    "\n",
    "        y = np.where(\n",
    "            d & post,\n",
    "            y11,\n",
    "            np.where(~d & post, y01, np.where(~d & ~post, y00, y10)),\n",
    "        )\n",
    "\n",
    "        # Gen id\n",
    "        id_ = np.repeat(np.arange(1, n + 1), 2)\n",
    "        time = np.tile([0, 1], n)\n",
    "\n",
    "        # Put in a long data frame\n",
    "        dta_long = pd.DataFrame(\n",
    "            {\n",
    "                \"id\": id_,\n",
    "                \"time\": time,\n",
    "                \"y\": np.tile(y, 2),\n",
    "                \"post\": np.tile(post.astype(int), 2),\n",
    "                \"d\": np.tile(d.astype(int), 2),\n",
    "                \"x1\": np.tile(z1, 2),\n",
    "                \"x2\": np.tile(z2, 2),\n",
    "                \"x3\": np.tile(z3, 2),\n",
    "                \"x4\": np.tile(z4, 2),\n",
    "            },\n",
    "        )\n",
    "        dta_long[\"post:d\"] = dta_long[\"post\"] * dta_long[\"d\"]\n",
    "        dta_long = dta_long.sort_values([\"id\", \"time\"])\n",
    "\n",
    "        # Run the IPW-DID estimator\n",
    "        covariates = dta_long[[\"x1\", \"x2\", \"x3\", \"x4\"]].values\n",
    "        y = dta_long[\"y\"].values\n",
    "        post = dta_long[\"post\"].values\n",
    "        D = dta_long[\"d\"].values\n",
    "\n",
    "        result = std_ipw_did_rc(y, post, D, covariates)\n",
    "\n",
    "        ATTE_estimates.append(result[\"ATT\"])\n",
    "        asymptotic_variance.append(result[\"se\"] ** 2)\n",
    "\n",
    "    # Calculate average bias, median bias, and RMSE\n",
    "    true_ATT = 0\n",
    "\n",
    "    # Bias calculations\n",
    "    biases = np.array(ATTE_estimates) - true_ATT\n",
    "    average_bias = np.mean(biases)\n",
    "    median_bias = np.median(biases)\n",
    "    average_variance = np.mean(asymptotic_variance)\n",
    "    # RMSE calculation\n",
    "    rmse = np.sqrt(np.mean(biases**2))\n",
    "\n",
    "    # Display the results\n",
    "    return {\n",
    "        \"Average Bias\": average_bias,\n",
    "        \"Median Bias\": median_bias,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Average Variance of ATT\": average_variance,\n",
    "    }\n",
    "\n",
    "\n",
    "ipw_sim_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit as logistic_cdf\n",
    "from scipy.stats import iqr, norm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def std_ipw_did_rc(\n",
    "    y,\n",
    "    post,\n",
    "    D,\n",
    "    covariates=None,\n",
    "    i_weights=None,\n",
    "    boot=False,\n",
    "    boot_type=\"weighted\",\n",
    "    nboot=None,\n",
    "    inffunc=False,\n",
    "):\n",
    "    # Convert inputs to numpy arrays\n",
    "    D = np.asarray(D).flatten()\n",
    "    n = len(D)\n",
    "    y = np.asarray(y).flatten()\n",
    "    post = np.asarray(post).flatten()\n",
    "\n",
    "    # Add constant to covariate vector\n",
    "    if covariates is None:\n",
    "        int_cov = np.ones((n, 1))\n",
    "    else:\n",
    "        covariates = np.asarray(covariates)\n",
    "        if np.all(covariates[:, 0] == 1):\n",
    "            int_cov = covariates\n",
    "        else:\n",
    "            int_cov = np.hstack((np.ones((n, 1)), covariates))\n",
    "\n",
    "    # Weights\n",
    "    if i_weights is None:\n",
    "        i_weights = np.ones(n)\n",
    "    elif np.min(i_weights) < 0:\n",
    "        msg = \"i.weights must be non-negative\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # Pscore estimation (logit) and its fitted values\n",
    "    model = LogisticRegression(fit_intercept=False, solver=\"lbfgs\")\n",
    "    model.fit(int_cov, D, sample_weight=i_weights)\n",
    "    ps_fit = model.predict_proba(int_cov)[:, 1]\n",
    "\n",
    "    # Do not divide by zero\n",
    "    ps_fit = np.clip(ps_fit, 1e-16, 1 - 1e-16)\n",
    "\n",
    "    # Compute IPW estimator\n",
    "    w_treat_pre = i_weights * D * (1 - post)\n",
    "    w_treat_post = i_weights * D * post\n",
    "    w_cont_pre = i_weights * ps_fit * (1 - D) * (1 - post) / (1 - ps_fit)\n",
    "    w_cont_post = i_weights * ps_fit * (1 - D) * post / (1 - ps_fit)\n",
    "\n",
    "    # Elements of the influence function (summands)\n",
    "    eta_treat_pre = w_treat_pre * y / np.mean(w_treat_pre)\n",
    "    eta_treat_post = w_treat_post * y / np.mean(w_treat_post)\n",
    "    eta_cont_pre = w_cont_pre * y / np.mean(w_cont_pre)\n",
    "    eta_cont_post = w_cont_post * y / np.mean(w_cont_post)\n",
    "\n",
    "    # Estimator of each component\n",
    "    att_treat_pre = np.mean(eta_treat_pre)\n",
    "    att_treat_post = np.mean(eta_treat_post)\n",
    "    att_cont_pre = np.mean(eta_cont_pre)\n",
    "    att_cont_post = np.mean(eta_cont_post)\n",
    "\n",
    "    # ATT estimator\n",
    "    ipw_att = (att_treat_post - att_treat_pre) - (att_cont_post - att_cont_pre)\n",
    "\n",
    "    # Get the influence function to compute standard error\n",
    "    score_ps = i_weights.reshape(-1, 1) * (D - ps_fit).reshape(-1, 1) * int_cov\n",
    "    hessian_ps = np.linalg.inv(np.dot(score_ps.T, score_ps) / n)\n",
    "    asy_lin_rep_ps = np.dot(score_ps, hessian_ps)\n",
    "\n",
    "    # Influence function of the \"treat\" component\n",
    "    inf_treat_pre = eta_treat_pre - w_treat_pre * att_treat_pre / np.mean(w_treat_pre)\n",
    "    inf_treat_post = eta_treat_post - w_treat_post * att_treat_post / np.mean(\n",
    "        w_treat_post,\n",
    "    )\n",
    "    inf_treat = inf_treat_post - inf_treat_pre\n",
    "\n",
    "    # Influence function of the control component\n",
    "    inf_cont_pre = eta_cont_pre - w_cont_pre * att_cont_pre / np.mean(w_cont_pre)\n",
    "    inf_cont_post = eta_cont_post - w_cont_post * att_cont_post / np.mean(w_cont_post)\n",
    "    inf_cont = inf_cont_post - inf_cont_pre\n",
    "\n",
    "    # Estimation effect from gamma hat (pscore)\n",
    "    M2_pre = np.mean(\n",
    "        w_cont_pre.reshape(-1, 1)\n",
    "        * (y - att_cont_pre).reshape(-1, 1)\n",
    "        * int_cov\n",
    "        / np.mean(w_cont_pre),\n",
    "        axis=0,\n",
    "    )\n",
    "    M2_post = np.mean(\n",
    "        w_cont_post.reshape(-1, 1)\n",
    "        * (y - att_cont_post).reshape(-1, 1)\n",
    "        * int_cov\n",
    "        / np.mean(w_cont_post),\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    inf_cont_ps = np.dot(asy_lin_rep_ps, (M2_post - M2_pre))\n",
    "    inf_cont += inf_cont_ps\n",
    "\n",
    "    # Influence function of the DR estimator\n",
    "    att_inf_func = inf_treat - inf_cont\n",
    "\n",
    "    if not boot:\n",
    "        # Estimate standard error\n",
    "        se_att = np.std(att_inf_func) / np.sqrt(n)\n",
    "        uci = ipw_att + 1.96 * se_att\n",
    "        lci = ipw_att - 1.96 * se_att\n",
    "        ipw_boot = None\n",
    "    else:\n",
    "        if nboot is None:\n",
    "            nboot = 999\n",
    "        if boot_type == \"multiplier\":\n",
    "            # Multiplier bootstrap\n",
    "            multipliers = np.random.normal(size=(nboot, n))\n",
    "            ipw_boot = [np.mean(m * att_inf_func) for m in multipliers]\n",
    "            se_att = iqr(ipw_boot) / (norm.ppf(0.75) - norm.ppf(0.25))\n",
    "            cv = np.percentile(np.abs(ipw_boot / se_att), 95)\n",
    "            uci = ipw_att + cv * se_att\n",
    "            lci = ipw_att - cv * se_att\n",
    "        else:\n",
    "            # Weighted bootstrap\n",
    "            ipw_boot = [\n",
    "                wboot_std_ipw_rc(n, y, post, D, int_cov, i_weights)\n",
    "                for _ in range(nboot)\n",
    "            ]\n",
    "            se_att = iqr(ipw_boot - ipw_att) / (norm.ppf(0.75) - norm.ppf(0.25))\n",
    "            cv = np.percentile(np.abs((ipw_boot - ipw_att) / se_att), 95)\n",
    "            uci = ipw_att + cv * se_att\n",
    "            lci = ipw_att - cv * se_att\n",
    "\n",
    "    if not inffunc:\n",
    "        att_inf_func = None\n",
    "\n",
    "    return {\n",
    "        \"ATT\": ipw_att,\n",
    "        \"se\": se_att,\n",
    "        \"uci\": uci,\n",
    "        \"lci\": lci,\n",
    "        \"boots\": ipw_boot,\n",
    "        \"att_inf_func\": att_inf_func,\n",
    "    }\n",
    "\n",
    "\n",
    "def wboot_std_ipw_rc(n, y, post, D, int_cov, i_weights):\n",
    "    boot_weights = np.random.choice(np.arange(1, n + 1), size=n, replace=True)\n",
    "    return std_ipw_did_rc(y, post, D, int_cov, i_weights=boot_weights)[\"ATT\"]\n",
    "\n",
    "\n",
    "# Simulation setup\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def ipw_sim_run():\n",
    "    # Define parameters\n",
    "    np.random.seed(42)  # You can use any integer value as the seed\n",
    "    # Sample size\n",
    "    n = 1000\n",
    "\n",
    "    # pscore index (strength of common support)\n",
    "    Xsi_ps = 0.75\n",
    "\n",
    "    # Proportion in each period\n",
    "\n",
    "    # Number of bootstrapped draws\n",
    "\n",
    "    # Mean and Std deviation of Z's without truncation\n",
    "    mean_z1 = np.exp(0.25 / 2)\n",
    "    sd_z1 = np.sqrt((np.exp(0.25) - 1) * np.exp(0.25))\n",
    "    mean_z2 = 10\n",
    "    sd_z2 = 0.54164\n",
    "    mean_z3 = 0.21887\n",
    "    sd_z3 = 0.04453\n",
    "    mean_z4 = 402\n",
    "    sd_z4 = 56.63891\n",
    "\n",
    "    # Initialize empty lists to store results\n",
    "    ATTE_estimates = []\n",
    "    asymptotic_variance = []\n",
    "    for _i in range(1000):\n",
    "        # Gen covariates\n",
    "        x1 = np.random.normal(0, 1, n)\n",
    "        x2 = np.random.normal(0, 1, n)\n",
    "        x3 = np.random.normal(0, 1, n)\n",
    "        x4 = np.random.normal(0, 1, n)\n",
    "\n",
    "        z1 = np.exp(x1 / 2)\n",
    "        z2 = x2 / (1 + np.exp(x1)) + 10\n",
    "        z3 = (x1 * x3 / 25 + 0.6) ** 3\n",
    "        z4 = (x1 + x4 + 20) ** 2\n",
    "\n",
    "        z1 = (z1 - mean_z1) / sd_z1\n",
    "        z2 = (z2 - mean_z2) / sd_z2\n",
    "        z3 = (z3 - mean_z3) / sd_z3\n",
    "        z4 = (z4 - mean_z4) / sd_z4\n",
    "\n",
    "        np.column_stack((x1, x2, x3, x4))\n",
    "        np.column_stack((z1, z2, z3, z4))\n",
    "\n",
    "        # Gen treatment groups\n",
    "        # Propensity score\n",
    "        pi = 1 / (1 + np.exp(-Xsi_ps * (-x1 + 0.5 * x2 - 0.25 * x3 - 0.1 * x4)))\n",
    "        d = np.random.rand(n) <= pi\n",
    "\n",
    "        # Generate aux indexes for the potential outcomes\n",
    "        index_lin = 210 + 27.4 * x1 + 13.7 * (x2 + x3 + x4)\n",
    "\n",
    "        # Create heterogeneous effects for the ATT, which is set approximately equal to zero\n",
    "        index_unobs_het = d * index_lin\n",
    "        index_att = 0\n",
    "\n",
    "        # This is the key for consistency of outcome regression\n",
    "        index_trend = 210 + 27.4 * x1 + 13.7 * (x2 + x3 + x4)\n",
    "\n",
    "        # v is the unobserved heterogeneity\n",
    "        v = np.random.normal(index_unobs_het, 1, n)\n",
    "\n",
    "        # Gen realized outcome at time 0\n",
    "        y00 = index_lin + v + np.random.normal(size=n)\n",
    "        y10 = index_lin + v + np.random.normal(size=n)\n",
    "\n",
    "        # Gen outcomes at time 1\n",
    "        # First let's generate potential outcomes: y_1_potential\n",
    "        y01 = index_lin + v + np.random.normal(size=n) + index_trend\n",
    "        y11 = index_lin + v + np.random.normal(size=n) + index_trend + index_att\n",
    "\n",
    "        # Generate \"T\"\n",
    "        ti_nt = 0.5\n",
    "        ti_t = 0.5\n",
    "        ti = d * ti_t + (1 - d) * ti_nt\n",
    "        post = np.random.rand(n) <= ti\n",
    "\n",
    "        # Combine outcomes into panel data format\n",
    "        y = np.where(\n",
    "            d & post,\n",
    "            y11,\n",
    "            np.where(~d & post, y01, np.where(~d & ~post, y00, y10)),\n",
    "        )\n",
    "\n",
    "        # Gen id\n",
    "        id_ = np.repeat(np.arange(1, n + 1), 2)\n",
    "        time = np.tile([0, 1], n)\n",
    "\n",
    "        # Put in a long data frame\n",
    "        dta_long = pd.DataFrame(\n",
    "            {\n",
    "                \"id\": id_,\n",
    "                \"time\": time,\n",
    "                \"y\": np.tile(y, 2),\n",
    "                \"post\": np.tile(post.astype(int), 2),\n",
    "                \"d\": np.tile(d.astype(int), 2),\n",
    "                \"x1\": np.tile(z1, 2),\n",
    "                \"x2\": np.tile(z2, 2),\n",
    "                \"x3\": np.tile(z3, 2),\n",
    "                \"x4\": np.tile(z4, 2),\n",
    "            },\n",
    "        )\n",
    "        dta_long[\"post:d\"] = dta_long[\"post\"] * dta_long[\"d\"]\n",
    "        dta_long = dta_long.sort_values([\"id\", \"time\"])\n",
    "\n",
    "        # Run the IPW-DID estimator\n",
    "        covariates = dta_long[[\"x1\", \"x2\", \"x3\", \"x4\"]].values\n",
    "        y = dta_long[\"y\"].values\n",
    "        post = dta_long[\"post\"].values\n",
    "        D = dta_long[\"d\"].values\n",
    "\n",
    "        result = std_ipw_did_rc(y, post, D, covariates)\n",
    "\n",
    "        ATTE_estimates.append(result[\"ATT\"])\n",
    "        asymptotic_variance.append(result[\"se\"] ** 2)\n",
    "\n",
    "    # Calculate average bias, median bias, and RMSE\n",
    "    true_ATT = 0\n",
    "\n",
    "    # Bias calculations\n",
    "    biases = np.array(ATTE_estimates) - true_ATT\n",
    "    average_bias = np.mean(biases)\n",
    "    median_bias = np.median(biases)\n",
    "    average_variance = np.mean(asymptotic_variance)\n",
    "    # RMSE calculation\n",
    "    rmse = np.sqrt(np.mean(biases**2))\n",
    "\n",
    "    # Display the results\n",
    "    return {\n",
    "        \"Average Bias\": average_bias,\n",
    "        \"Median Bias\": median_bias,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Average Variance of ATT\": average_variance,\n",
    "    }\n",
    "\n",
    "\n",
    "ipw_sim_run()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
