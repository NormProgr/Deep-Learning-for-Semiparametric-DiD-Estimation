{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import logistic, norm\n",
    "\n",
    "\n",
    "def twfe_DGP1_simulation():\n",
    "    \"\"\"Perform the DGP1 simulation as per the given specifications.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints the results of the simulation.\n",
    "\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # You can use any integer value as the seed\n",
    "\n",
    "    # Define parameters\n",
    "    n = 1000  # Sample size\n",
    "    Xsi_ps = 0.75  # pscore index\n",
    "    _lambda = 0.5  # Proportion in each period\n",
    "\n",
    "    # Define means and standard deviations\n",
    "    mean_z1 = np.exp(0.25 / 2)\n",
    "    sd_z1 = np.sqrt((np.exp(0.25) - 1) * np.exp(0.25))\n",
    "    mean_z2 = 10\n",
    "    sd_z2 = 0.54164\n",
    "    mean_z3 = 0.21887\n",
    "    sd_z3 = 0.04453\n",
    "    mean_z4 = 402\n",
    "    sd_z4 = 56.63891\n",
    "\n",
    "    # Initialize empty lists to store results\n",
    "    ATTE_estimates = []\n",
    "    asymptotic_variance = []\n",
    "    ATTE_estimates_corr = []\n",
    "    asymptotic_variance_corr = []\n",
    "\n",
    "    coverage_prob = []\n",
    "    coverage_prob_corr = []\n",
    "    # Loop for 1000 runs\n",
    "    for _i in range(1000):\n",
    "        # Generate covariates\n",
    "        x1 = np.random.normal(0, 1, n)\n",
    "        x2 = np.random.normal(0, 1, n)\n",
    "        x3 = np.random.normal(0, 1, n)\n",
    "        x4 = np.random.normal(0, 1, n)\n",
    "\n",
    "        z1 = np.exp(x1 / 2)\n",
    "        z2 = x2 / (1 + np.exp(x1)) + 10\n",
    "        z3 = (x1 * x3 / 25 + 0.6) ** 3\n",
    "        z4 = (x1 + x4 + 20) ** 2\n",
    "\n",
    "        z1 = (z1 - mean_z1) / sd_z1\n",
    "        z2 = (z2 - mean_z2) / sd_z2\n",
    "        z3 = (z3 - mean_z3) / sd_z3\n",
    "        z4 = (z4 - mean_z4) / sd_z4\n",
    "\n",
    "        np.column_stack((x1, x2, x3, x4))\n",
    "        np.column_stack((z1, z2, z3, z4))\n",
    "\n",
    "        # Propensity score\n",
    "        pi = logistic.cdf(Xsi_ps * (-z1 + 0.5 * z2 - 0.25 * z3 - 0.1 * z4))\n",
    "        d = np.random.uniform(size=n) <= pi\n",
    "\n",
    "        # Generate aux indexes for the potential outcomes\n",
    "        index_lin = 210 + 27.4 * z1 + 13.7 * (z2 + z3 + z4)\n",
    "        index_unobs_het = d * (index_lin)\n",
    "        index_att = 0\n",
    "        index_trend = 210 + 27.4 * z1 + 13.7 * (z2 + z3 + z4)\n",
    "\n",
    "        # Generate unobserved heterogeneity\n",
    "        v = np.random.normal(index_unobs_het, 1)\n",
    "\n",
    "        # Generate outcomes at time 0 and time 1\n",
    "        y00 = index_lin + v + np.random.normal(size=n)\n",
    "        y10 = index_lin + v + np.random.normal(size=n)\n",
    "        y01 = index_lin + v + np.random.normal(scale=1, size=n) + index_trend\n",
    "        y11 = (\n",
    "            index_lin + v + np.random.normal(scale=1, size=n) + index_trend + index_att\n",
    "        )\n",
    "\n",
    "        # Generate \"T\"\n",
    "        ti_nt = 0.5\n",
    "        ti_t = 0.5\n",
    "        ti = d * ti_t + (1 - d) * ti_nt\n",
    "        post = np.random.uniform(size=n) <= ti\n",
    "\n",
    "        y = np.where(\n",
    "            d & post,\n",
    "            y11,\n",
    "            np.where(~d & post, y01, np.where(~d & ~post, y00, y10)),\n",
    "        )\n",
    "\n",
    "        # Generate id\n",
    "        id_ = np.repeat(np.arange(1, n + 1), 2)\n",
    "        time = np.tile([0, 1], n)\n",
    "        # Put in a long data frame\n",
    "        dta_long = pd.DataFrame(\n",
    "            {\n",
    "                \"id\": id_,\n",
    "                \"time\": time,\n",
    "                \"y\": np.tile(y, 2),\n",
    "                \"post\": np.tile(post.astype(int), 2),\n",
    "                \"d\": np.tile(d.astype(int), 2),\n",
    "                \"x1\": np.tile(z1, 2),\n",
    "                \"x2\": np.tile(z2, 2),\n",
    "                \"x3\": np.tile(z3, 2),\n",
    "                \"x4\": np.tile(z4, 2),\n",
    "            },\n",
    "        )\n",
    "        dta_long[\"post:d\"] = dta_long[\"post\"] * dta_long[\"d\"]\n",
    "\n",
    "        dta_long = dta_long.sort_values([\"id\", \"time\"])\n",
    "\n",
    "        # Perform TWFE estimation\n",
    "        twfe_i = sm.OLS(\n",
    "            dta_long[\"y\"],\n",
    "            sm.add_constant(dta_long[[\"x1\", \"x2\", \"x3\", \"x4\", \"post\", \"d\", \"post:d\"]]),\n",
    "        ).fit()\n",
    "        twfe = twfe_i.params[\"post:d\"]\n",
    "\n",
    "        # Calculate asymptotic variance\n",
    "        asymptotic_variance.append(twfe_i.cov_params().loc[\"post:d\", \"post:d\"])\n",
    "\n",
    "        # Append TWFE estimate to the list\n",
    "        ATTE_estimates.append(twfe)\n",
    "        # Calculate coverage probability for Standard TWFE\n",
    "        lower_bound = twfe - norm.ppf(0.975) * np.sqrt(twfe_i.cov_params()[\"post:d\"])\n",
    "        upper_bound = twfe + norm.ppf(0.975) * np.sqrt(twfe_i.cov_params()[\"post:d\"])\n",
    "        coverage_prob.append(1 if lower_bound <= 0 <= upper_bound else 0)\n",
    "\n",
    "        # correct version of twfe\n",
    "        for var in [\"x1\", \"x2\", \"x3\", \"x4\"]:\n",
    "            dta_long[f\"{var}:d\"] = dta_long[var] * dta_long[\"d\"]\n",
    "            dta_long[f\"{var}:post\"] = dta_long[var] * dta_long[\"post\"]\n",
    "            dta_long[f\"{var}:post:d\"] = dta_long[var] * dta_long[\"post\"] * dta_long[\"d\"]\n",
    "        independent_vars = [\n",
    "            \"x1\",\n",
    "            \"x2\",\n",
    "            \"x3\",\n",
    "            \"x4\",\n",
    "            \"post\",\n",
    "            \"d\",\n",
    "            \"post:d\",\n",
    "            \"x1:d\",\n",
    "            \"x2:d\",\n",
    "            \"x3:d\",\n",
    "            \"x4:d\",\n",
    "            \"x1:post\",\n",
    "            \"x2:post\",\n",
    "            \"x3:post\",\n",
    "            \"x4:post\",\n",
    "            \"x1:post:d\",\n",
    "            \"x2:post:d\",\n",
    "            \"x3:post:d\",\n",
    "            \"x4:post:d\",\n",
    "        ]\n",
    "        twfe_corr_i = sm.OLS(\n",
    "            dta_long[\"y\"],\n",
    "            sm.add_constant(dta_long[independent_vars]),\n",
    "        ).fit()\n",
    "        twfe_corr = twfe_corr_i.params[\"post:d\"]\n",
    "        asymptotic_variance_corr.append(twfe_corr_i.cov_params()[\"post:d\"])\n",
    "        ATTE_estimates_corr.append(twfe_corr)\n",
    "\n",
    "        lower_bound_corr = twfe_corr - norm.ppf(0.975) * np.sqrt(\n",
    "            twfe_corr_i.cov_params()[\"post:d\"],\n",
    "        )\n",
    "        upper_bound_corr = twfe_corr + norm.ppf(0.975) * np.sqrt(\n",
    "            twfe_corr_i.cov_params()[\"post:d\"],\n",
    "        )\n",
    "        coverage_prob_corr.append(1 if lower_bound_corr <= 0 <= upper_bound_corr else 0)\n",
    "\n",
    "    # Convert lists to arrays for ease of calculation\n",
    "    ATTE_estimates = np.array(ATTE_estimates)\n",
    "    asymptotic_variance = np.array(asymptotic_variance)\n",
    "    asymptotic_variance = asymptotic_variance.reshape(-1, 8)\n",
    "    asymptotic_variance = asymptotic_variance[:, 0]\n",
    "\n",
    "    # Calculate metrics\n",
    "    avg_bias = np.mean(\n",
    "        ATTE_estimates - 0,\n",
    "    )  # Assuming ATTE is 0 as mentioned in the code\n",
    "    med_bias = np.median(\n",
    "        ATTE_estimates - 0,\n",
    "    )  # Assuming ATTE is 0 as mentioned in the code\n",
    "    rmse = np.sqrt(\n",
    "        np.mean((ATTE_estimates - 0) ** 2),\n",
    "    )  # Assuming ATTE is 0 as mentioned in the code\n",
    "    variance_ATT = np.var(ATTE_estimates)\n",
    "\n",
    "    ATTE_estimates_corr = np.array(ATTE_estimates_corr)\n",
    "    asymptotic_variance_corr = np.array(asymptotic_variance_corr)\n",
    "    asymptotic_variance_corr = asymptotic_variance_corr.reshape(-1, 8)\n",
    "    asymptotic_variance_corr = asymptotic_variance_corr[:, 0]\n",
    "    avg_bias_corr = np.mean(\n",
    "        ATTE_estimates_corr - 0,\n",
    "    )\n",
    "    med_bias_corr = np.median(\n",
    "        ATTE_estimates_corr - 0,\n",
    "    )\n",
    "    rmse_corr = np.sqrt(\n",
    "        np.mean((ATTE_estimates_corr - 0) ** 2),\n",
    "    )\n",
    "    variance_ATT_corr = np.var(ATTE_estimates_corr)\n",
    "    coverage_prob = np.mean(coverage_prob)\n",
    "    coverage_prob_corr = np.mean(coverage_prob_corr)\n",
    "    return {\n",
    "        \"Average Bias\": avg_bias,\n",
    "        \"Median Bias\": med_bias,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Average Variance of ATT\": variance_ATT,\n",
    "        \"Coverage Probability\": coverage_prob,\n",
    "        \"Average Bias_corr\": avg_bias_corr,\n",
    "        \"Median Bias_corr\": med_bias_corr,\n",
    "        \"RMSE_corr\": rmse_corr,\n",
    "        \"Average Variance of ATT_corr\": variance_ATT_corr,\n",
    "        \"Coverage Probability_corr\": coverage_prob_corr,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = twfe_DGP1_simulation()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import logistic, norm\n",
    "\n",
    "\n",
    "def twfe_DGP1_simulation():\n",
    "    \"\"\"Perform the DGP1 simulation as per the given specifications.\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains various metrics from the simulation.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # You can use any integer value as the seed\n",
    "\n",
    "    # Define parameters\n",
    "    n = 1000  # Sample size\n",
    "    Xsi_ps = 0.75  # pscore index\n",
    "    _lambda = 0.5  # Proportion in each period\n",
    "\n",
    "    # Define means and standard deviations\n",
    "    mean_z1 = np.exp(0.25 / 2)\n",
    "    sd_z1 = np.sqrt((np.exp(0.25) - 1) * np.exp(0.25))\n",
    "    mean_z2 = 10\n",
    "    sd_z2 = 0.54164\n",
    "    mean_z3 = 0.21887\n",
    "    sd_z3 = 0.04453\n",
    "    mean_z4 = 402\n",
    "    sd_z4 = 56.63891\n",
    "\n",
    "    # Initialize empty lists to store results\n",
    "    ATTE_estimates = []\n",
    "    asymptotic_variance = []\n",
    "    ATTE_estimates_corr = []\n",
    "    asymptotic_variance_corr = []\n",
    "\n",
    "    coverage_prob = []\n",
    "    coverage_prob_corr = []\n",
    "\n",
    "    # Loop for 1000 runs\n",
    "    for _i in range(1000):\n",
    "        # Generate covariates\n",
    "        x1 = np.random.normal(0, 1, n)\n",
    "        x2 = np.random.normal(0, 1, n)\n",
    "        x3 = np.random.normal(0, 1, n)\n",
    "        x4 = np.random.normal(0, 1, n)\n",
    "\n",
    "        z1 = np.exp(x1 / 2)\n",
    "        z2 = x2 / (1 + np.exp(x1)) + 10\n",
    "        z3 = (x1 * x3 / 25 + 0.6) ** 3\n",
    "        z4 = (x1 + x4 + 20) ** 2\n",
    "\n",
    "        z1 = (z1 - mean_z1) / sd_z1\n",
    "        z2 = (z2 - mean_z2) / sd_z2\n",
    "        z3 = (z3 - mean_z3) / sd_z3\n",
    "        z4 = (z4 - mean_z4) / sd_z4\n",
    "\n",
    "        np.column_stack((x1, x2, x3, x4))\n",
    "        np.column_stack((z1, z2, z3, z4))\n",
    "\n",
    "        # Propensity score\n",
    "        pi = logistic.cdf(Xsi_ps * (-z1 + 0.5 * z2 - 0.25 * z3 - 0.1 * z4))\n",
    "        d = np.random.uniform(size=n) <= pi\n",
    "\n",
    "        # Generate aux indexes for the potential outcomes\n",
    "        index_lin = 210 + 27.4 * z1 + 13.7 * (z2 + z3 + z4)\n",
    "        index_unobs_het = d * (index_lin)\n",
    "        index_att = 0\n",
    "        index_trend = 210 + 27.4 * z1 + 13.7 * (z2 + z3 + z4)\n",
    "\n",
    "        # Generate unobserved heterogeneity\n",
    "        v = np.random.normal(index_unobs_het, 1)\n",
    "\n",
    "        # Generate outcomes at time 0 and time 1\n",
    "        y00 = index_lin + v + np.random.normal(size=n)\n",
    "        y10 = index_lin + v + np.random.normal(size=n)\n",
    "        y01 = index_lin + v + np.random.normal(scale=1, size=n) + index_trend\n",
    "        y11 = (\n",
    "            index_lin + v + np.random.normal(scale=1, size=n) + index_trend + index_att\n",
    "        )\n",
    "\n",
    "        # Generate \"T\"\n",
    "        ti_nt = 0.5\n",
    "        ti_t = 0.5\n",
    "        ti = d * ti_t + (1 - d) * ti_nt\n",
    "        post = np.random.uniform(size=n) <= ti\n",
    "\n",
    "        y = np.where(\n",
    "            d & post,\n",
    "            y11,\n",
    "            np.where(~d & post, y01, np.where(~d & ~post, y00, y10)),\n",
    "        )\n",
    "\n",
    "        # Generate id\n",
    "        id_ = np.repeat(np.arange(1, n + 1), 2)\n",
    "        time = np.tile([0, 1], n)\n",
    "        # Put in a long data frame\n",
    "        dta_long = pd.DataFrame(\n",
    "            {\n",
    "                \"id\": id_,\n",
    "                \"time\": time,\n",
    "                \"y\": np.tile(y, 2),\n",
    "                \"post\": np.tile(post.astype(int), 2),\n",
    "                \"d\": np.tile(d.astype(int), 2),\n",
    "                \"x1\": np.tile(z1, 2),\n",
    "                \"x2\": np.tile(z2, 2),\n",
    "                \"x3\": np.tile(z3, 2),\n",
    "                \"x4\": np.tile(z4, 2),\n",
    "            },\n",
    "        )\n",
    "        dta_long[\"post:d\"] = dta_long[\"post\"] * dta_long[\"d\"]\n",
    "\n",
    "        dta_long = dta_long.sort_values([\"id\", \"time\"])\n",
    "\n",
    "        # Perform TWFE estimation\n",
    "        twfe_i = sm.OLS(\n",
    "            dta_long[\"y\"],\n",
    "            sm.add_constant(dta_long[[\"x1\", \"x2\", \"x3\", \"x4\", \"post\", \"d\", \"post:d\"]]),\n",
    "        ).fit()\n",
    "        twfe = twfe_i.params[\"post:d\"]\n",
    "\n",
    "        # Calculate asymptotic variance\n",
    "        asymptotic_variance.append(twfe_i.cov_params().loc[\"post:d\", \"post:d\"])\n",
    "\n",
    "        # Append TWFE estimate to the list\n",
    "        ATTE_estimates.append(twfe)\n",
    "\n",
    "        # Calculate coverage probability for Standard TWFE\n",
    "        lower_bound = twfe - norm.ppf(0.975) * np.sqrt(\n",
    "            twfe_i.cov_params().loc[\"post:d\", \"post:d\"],\n",
    "        )\n",
    "        upper_bound = twfe + norm.ppf(0.975) * np.sqrt(\n",
    "            twfe_i.cov_params().loc[\"post:d\", \"post:d\"],\n",
    "        )\n",
    "        coverage_prob.append(1 if lower_bound <= 0 <= upper_bound else 0)\n",
    "\n",
    "        # correct version of twfe\n",
    "        for var in [\"x1\", \"x2\", \"x3\", \"x4\"]:\n",
    "            dta_long[f\"{var}:d\"] = dta_long[var] * dta_long[\"d\"]\n",
    "            dta_long[f\"{var}:post\"] = dta_long[var] * dta_long[\"post\"]\n",
    "            dta_long[f\"{var}:post:d\"] = dta_long[var] * dta_long[\"post\"] * dta_long[\"d\"]\n",
    "        independent_vars = [\n",
    "            \"x1\",\n",
    "            \"x2\",\n",
    "            \"x3\",\n",
    "            \"x4\",\n",
    "            \"post\",\n",
    "            \"d\",\n",
    "            \"post:d\",\n",
    "            \"x1:d\",\n",
    "            \"x2:d\",\n",
    "            \"x3:d\",\n",
    "            \"x4:d\",\n",
    "            \"x1:post\",\n",
    "            \"x2:post\",\n",
    "            \"x3:post\",\n",
    "            \"x4:post\",\n",
    "            \"x1:post:d\",\n",
    "            \"x2:post:d\",\n",
    "            \"x3:post:d\",\n",
    "            \"x4:post:d\",\n",
    "        ]\n",
    "        twfe_corr_i = sm.OLS(\n",
    "            dta_long[\"y\"],\n",
    "            sm.add_constant(dta_long[independent_vars]),\n",
    "        ).fit()\n",
    "        twfe_corr = twfe_corr_i.params[\"post:d\"]\n",
    "        asymptotic_variance_corr.append(\n",
    "            twfe_corr_i.cov_params().loc[\"post:d\", \"post:d\"],\n",
    "        )\n",
    "        ATTE_estimates_corr.append(twfe_corr)\n",
    "\n",
    "        lower_bound_corr = twfe_corr - norm.ppf(0.975) * np.sqrt(\n",
    "            twfe_corr_i.cov_params().loc[\"post:d\", \"post:d\"],\n",
    "        )\n",
    "        upper_bound_corr = twfe_corr + norm.ppf(0.975) * np.sqrt(\n",
    "            twfe_corr_i.cov_params().loc[\"post:d\", \"post:d\"],\n",
    "        )\n",
    "        coverage_prob_corr.append(1 if lower_bound_corr <= 0 <= upper_bound_corr else 0)\n",
    "\n",
    "    # Convert lists to arrays for ease of calculation\n",
    "    ATTE_estimates = np.array(ATTE_estimates)\n",
    "    asymptotic_variance = np.array(asymptotic_variance)\n",
    "    asymptotic_variance = asymptotic_variance.reshape(-1, 8)\n",
    "    asymptotic_variance = asymptotic_variance[:, 0]\n",
    "\n",
    "    # Calculate metrics\n",
    "    avg_bias = np.mean(\n",
    "        ATTE_estimates - 0,\n",
    "    )  # Assuming ATTE is 0 as mentioned in the code\n",
    "    med_bias = np.median(\n",
    "        ATTE_estimates - 0,\n",
    "    )  # Assuming ATTE is 0 as mentioned in the code\n",
    "    rmse = np.sqrt(\n",
    "        np.mean((ATTE_estimates - 0) ** 2),\n",
    "    )  # Assuming ATTE is 0 as mentioned in the code\n",
    "    variance_ATT = np.var(ATTE_estimates)\n",
    "\n",
    "    ATTE_estimates_corr = np.array(ATTE_estimates_corr)\n",
    "    asymptotic_variance_corr = np.array(asymptotic_variance_corr)\n",
    "    asymptotic_variance_corr = asymptotic_variance_corr.reshape(-1, 8)\n",
    "    asymptotic_variance_corr = asymptotic_variance_corr[:, 0]\n",
    "    avg_bias_corr = np.mean(\n",
    "        ATTE_estimates_corr - 0,\n",
    "    )\n",
    "    med_bias_corr = np.median(\n",
    "        ATTE_estimates_corr - 0,\n",
    "    )\n",
    "    rmse_corr = np.sqrt(\n",
    "        np.mean((ATTE_estimates_corr - 0) ** 2),\n",
    "    )\n",
    "    variance_ATT_corr = np.var(ATTE_estimates_corr)\n",
    "    coverage_prob = np.mean(coverage_prob)\n",
    "    coverage_prob_corr = np.mean(coverage_prob_corr)\n",
    "\n",
    "    return {\n",
    "        \"Average Bias\": avg_bias,\n",
    "        \"Median Bias\": med_bias,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Average Variance of ATT\": variance_ATT,\n",
    "        \"Coverage Probability\": coverage_prob,\n",
    "        \"Average Bias_corr\": avg_bias_corr,\n",
    "        \"Median Bias_corr\": med_bias_corr,\n",
    "        \"RMSE_corr\": rmse_corr,\n",
    "        \"Average Variance of ATT_corr\": variance_ATT_corr,\n",
    "        \"Coverage Probability_corr\": coverage_prob_corr,\n",
    "    }\n",
    "\n",
    "\n",
    "results = twfe_DGP1_simulation()\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
